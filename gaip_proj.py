# -*- coding: utf-8 -*-
"""gaip-proj.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MuQZfVDU2EyYFoA6pKqsEqZV0gQ-1XvH
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import numpy as np
import pandas as pd

from PIL import Image
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches

import torch
from torch import nn
from torch import optim
import torch.optim as optim
import torch.nn.functional as F
from torchvision import transforms, models
from torch.autograd import Variable
from torchvision.datasets import ImageFolder
import torch.utils.data as data
from torch.utils.data import DataLoader, TensorDataset

from torchsummary import summary

DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
print(DEVICE)

import shutil
import os

original_dataset_dir = '/content/drive/MyDrive/Train_segregated'                  # train
classes_list = os.listdir(original_dataset_dir)

# base_dir = './Split'                              # train-validation
# os.mkdir(base_dir)

train_dir = '/content/drive/MyDrive/Train_segregated'      # train data

validation_dir = '/content/drive/MyDrive/Test_segregated'    # validation data


# for cls in classes_list:
#     os.mkdir(os.path.join(train_dir, cls))
#     os.mkdir(os.path.join(validation_dir, cls))

BATCH_SIZE = 5
EPOCH = 10

data_transforms = {
    'train': transforms.Compose([
        transforms.ToTensor(),
        transforms.CenterCrop(224),         # crop to 400
        transforms.RandomHorizontalFlip(),  # Horizontal Flip Randomly(p=50)
        transforms.Grayscale(num_output_channels = 1)]),

    'val': transforms.Compose([
        transforms.ToTensor(),
        transforms.CenterCrop(224),         # crop to 400
        transforms.Grayscale(num_output_channels = 1)])
}


train_dataset = ImageFolder(root='/content/drive/MyDrive/MURA_subset/train', transform = data_transforms['train'])
val_dataset = ImageFolder(root='/content/drive/MyDrive/MURA_subset/valid', transform = data_transforms['val'])

train_loader = torch.utils.data.DataLoader(train_dataset,
                                           batch_size=BATCH_SIZE,
                                           shuffle=True,
                                           num_workers=4)
val_loader = torch.utils.data.DataLoader(val_dataset,
                                         batch_size=BATCH_SIZE,
                                         shuffle=True,
                                         num_workers=4)
val_loader

# Display images
# Not necessary for training. Just for confirmation
for images, labels in val_loader:

        i, l = Variable(images), Variable(labels)
        print(i.size())
        i = i.numpy()
        l = l.numpy()
        if l[0]==0:
            print('Label = {} : Normal image'.format(l[0]))
        else:
            print('Label = {} : Fracture image'.format(l[0]))
        plt.imshow(i[0,0,:,:])
        plt.show()

# Build convolutional neural net
class AlexNet(nn.Module): # AlexNet 모델 설계
    def __init__(self, n_classes = 1):
        super(AlexNet, self).__init__()

        # 1st conv layer
        self.Conv_1 = nn.Sequential(
          nn.Conv2d(in_channels = 1, out_channels = 96, kernel_size = 11, stride = 4, padding = 0),
          nn.ReLU(),
          nn.MaxPool2d(kernel_size = 3, stride = 2),
          nn.BatchNorm2d(96))

        # 2nd conv layer
        self.Conv_2 = nn.Sequential(
          nn.Conv2d(in_channels = 96, out_channels = 256, kernel_size = 5, stride = 1, padding = 2),
          nn.ReLU(),
          nn.MaxPool2d(kernel_size = 3, stride = 2),
          nn.BatchNorm2d(256))

        # 3rd conv layer
        self.Conv_3 = nn.Sequential(
          nn.Conv2d(in_channels = 256, out_channels = 384, kernel_size = 3, stride = 1, padding = 1),
          nn.ReLU())

        # 4th conv layer
        self.Conv_4 = nn.Sequential(
          nn.Conv2d(in_channels = 384, out_channels = 384, kernel_size = 3, stride = 1, padding = 1),
          nn.ReLU())

        # 5th conv layer
        self.Conv_5 = nn.Sequential(
          nn.Conv2d(in_channels = 384, out_channels = 256, kernel_size = 3, stride = 1, padding = 1),
          nn.ReLU(),
          nn.MaxPool2d(kernel_size = 3, stride = 2))

        # # 6th conv layer
        # self.Conv_6 = nn.Sequential(
        #   nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1, padding = 1),
        #   nn.ReLU(),
        #   nn.MaxPool2d(kernel_size = 3, stride = 2))

        # 1st fully connected layer
        self.FC1 = nn.Sequential(
          nn.Flatten(),
          nn.Dropout(0.8),
          nn.Linear(256*11*11, 4096),
          nn.ReLU())

        # 2nd fully connected layer
        self.FC2 = nn.Sequential(
          nn.Dropout(0.8),
          nn.Linear(4096, 4096),
          nn.ReLU())

        # 3rd fully connected layer --> output layer
        self.FC3 = nn.Sequential(
          nn.Linear(4096, n_classes))

    def forward(self, x):   # AlexNet forward propagation
        x = self.Conv_1(x)
        x = self.Conv_2(x)
        x = self.Conv_3(x)
        x = self.Conv_4(x)
        x = self.Conv_5(x)
        # x = self.Conv_6(x)
        x = self.FC1(x)
        x = self.FC2(x)
        x = self.FC3(x)

        return F.log_softmax(x) # softmax 통해 최종 output 계산

model = AlexNet().to(DEVICE)  # 모델 GPU로
model # Print network

summary(model, (1, 400, 400))

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)

def train(model, train_loader, optimizer):
    model.train()                         # 모델 train 상태로
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(DEVICE), target.to(DEVICE)  # data, target 값 DEVICE에 할당
        optimizer.zero_grad()                              # optimizer gradient 값 초기화
        output = model(data)
        print(target.shape,output.shape)
        target = target.resize_(output.shape[0],1)
        # print(target.shape,output.shape)
        target = target.type(torch.FloatTensor)
        output = output.type(torch.FloatTensor)
                                       # 할당된 데이터로 output 계산
        loss =  criterion(output, target)                  # Cross Entropy Loss 사용해 loss 계산
        loss.backward()                                    # 계산된 loss back propagation
        optimizer.step()                                   # parameter update

def evaluate(model, test_loader):
    model.eval()      # 모델 평가 상태로
    test_loss = 0     # test_loss 초기화
    correct = 0       # 맞게 예측한 0 값으로 초기화

    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(DEVICE), target.to(DEVICE)     # data, target DEVICE에 할당
            output = model(data)                                  # output 계산
            test_loss += criterion(output, target).item()         # loss 계산(총 loss 에 더해주기)
            pred = output.max(1, keepdim=True)[1]                 # 계산된 벡터값 중 가장 큰 값 가지는 class 예측
            correct += pred.eq(target.view_as(pred)).sum().item() # 맞게 예측한 값 세기

    test_loss /= len(test_loader.dataset)                         # 평균 loss
    test_accuracy = 100. * correct / len(test_loader.dataset)     # test(validation) 데이터 정확도
    return test_loss, test_accuracy

import time
import copy

def train_model(model ,train_loader, val_loader, optimizer, num_epochs = 1):
    acc_t = []; acc_v = []    # train, validation accuracy 저장할 list
    loss_t = []; loss_v = []  # train, validation loss 저장할 list

    best_acc = 0.0  # beset accuracy 초기화
    best_model_wts = copy.deepcopy(model.state_dict())

    for epoch in range(1, num_epochs + 1):
        since = time.time()
        print(epoch)                                    # 학습 시간 계산
        train(model, train_loader, optimizer)

                           # train 데이터로 학습
        train_loss, train_acc = evaluate(model, train_loader)   # train_loss, train_acc 계산
        val_loss, val_acc = evaluate(model, val_loader)         # valid_loss, valid_acc 계산

        if val_acc>best_acc:  # update best accuracy
            best_acc = val_acc
            best_model_wts = copy.deepcopy(model.state_dict())  # 가장 accuracy 높은 model 저장

        # loss, accuarcy 저장하기
        acc_t.append(train_acc); acc_v.append(val_acc)
        loss_t.append(train_loss);loss_v.append(val_loss)

        #학습 결과 및 시간 출력
        time_elapsed = time.time() - since
        print('-------------- EPOCH {} ----------------'.format(epoch))
        print('Train Loss: {:.4f}, Accuracy: {:.2f}%'.format(train_loss, train_acc))
        print('Val Loss: {:.4f}, Accuracy: {:.2f}%'.format(val_loss, val_acc))
        print('Time: {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
        print()

    # Accuracy Graph
    plt.plot(range(len(acc_t)), acc_t, 'b', range(len(acc_v)), acc_v, 'r')
    blue_patch = mpatches.Patch(color='blue', label='Train Accuracy')
    red_patch = mpatches.Patch(color='red', label='Validation Accuracy')
    plt.legend(handles=[red_patch, blue_patch])
    plt.show()

    # Loss Graph
    plt.plot(range(len(loss_t)), loss_t, 'b', range(len(loss_v)), loss_v, 'r')
    blue_patch = mpatches.Patch(color='blue', label='Train Loss')
    red_patch = mpatches.Patch(color='red', label='Validation Loss')
    plt.legend(handles=[red_patch, blue_patch])
    plt.show()

    model.load_state_dict(best_model_wts) # validation accuracy, 가장 높은 모델 저장
    return model

# weight decay = 1e-4
model = train_model(model ,train_loader, val_loader, optimizer, 5)

#importing the necessary libraries
import tensorflow as tf
from tensorflow.keras import layers
from skimage.io import imshow
from pathlib import Path
import pandas as pd

# Input data files are available in the "../mura_unzipped/" directory.
# Running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

import os
print(os.listdir("/content/drive/MyDrive/MURA-2/MURA-2"))

dataset_root = Path('/content/drive/MyDrive/MURA-2/MURA-2')

list(dataset_root.iterdir())

#df is the generated dataframe whose head can be visualized below
df = pd.read_csv('/content/drive/MyDrive/MURA-2/MURA-2/train_image_paths.csv', header=None, names=['filename'])
df.head()

#Adding class column to the dataframe with positive or negative label
#Classification is done on basis of the image names (postive/negative)
df['class'] = (df.filename.str.extract('study.*_(positive|negative)'))
df.head()

#A function to generate the dataframe for a csv file
def generate_df(csv_name):
    df = pd.read_csv(csv_name, header=None, names=['filename'])
    df['class'] = (df.filename
               .str.extract('study.*_(positive|negative)'))
    return df

list(dataset_root.iterdir())

#Dividing the image data generated into train set and validation set
datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1. / 255)
#Creating training set
train_gen = datagen.flow_from_dataframe(generate_df('/content/drive/MyDrive/MURA-2/MURA-2/train_image_paths.csv'),
                                        directory=dataset_root.parent,
                                        target_size=(224, 224),
                                        class_mode='binary')
#Creating validation set
valid_gen = datagen.flow_from_dataframe(generate_df('/content/drive/MyDrive/MURA-2/MURA-2/valid_image_paths.csv'),
                                        directory=dataset_root.parent,
                                        target_size=(224, 224),
                                        class_mode='binary')

#Downloading the densenet model pretrained on the imagenet dataset
densenet = tf.keras.applications.DenseNet169(weights='imagenet', include_top = False, input_shape=(224, 224, 3))

#Freezing the weights of the pretrained model
densenet.trainable = False

